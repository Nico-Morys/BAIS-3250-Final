{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20edb176-3a3a-4ca3-aa0a-8878d45b5855",
   "metadata": {},
   "source": [
    "### Jacob Kopec and Nico Morys\n",
    "### Data Wrangling Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0df48-fc6d-40b2-8f8a-5b422134a7b3",
   "metadata": {},
   "source": [
    "### The code below can be used to scrape IMDb's Top 1000 Highest Rated Movies of All Time list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d0a9d9-d4d8-4e35-b5bc-b085c2f6d9b5",
   "metadata": {},
   "source": [
    "#### The link to the list is here: https://www.imdb.com/search/title/?groups=top_1000&count=100&sort=user_rating,desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75aaa7a-6e2f-4c14-8186-9b21cf5d4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pandas and selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By # used to import different ways to access data in the XML or HTML file\n",
    "from selenium.webdriver.chrome.service import Service # no longer need to download a driver file, use service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager # used to manage the Chrome driver to emulate a Chrome web browser\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a98474d-bdeb-46a2-bfea-1e09d5fd6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping the 1st set of 100...\n",
      "Scraping the 2nd set of 100...\n",
      "Scraping the 3rd set of 100...\n",
      "Scraping the 4th set of 100...\n",
      "Scraping the 5th set of 100...\n",
      "Scraping the 6th set of 100...\n",
      "Scraping the 7th set of 100...\n",
      "Scraping the 8th set of 100...\n",
      "Scraping the 9th set of 100...\n",
      "Scraping the 10th set of 100...\n",
      "100 more button not found\n",
      "Length of Name: 1000\n",
      "Length of Date: 1000\n",
      "Length of ARating: 1000\n"
     ]
    }
   ],
   "source": [
    "#path to chrome (personal to my computer)\n",
    "chromedriver_path = r'C://Users//nicom//.wdm//drivers//chromedriver//win64//chromedriver.exe'\n",
    "\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "\n",
    "#initializes the browser\n",
    "browser = webdriver.Chrome(service=service)\n",
    "\n",
    "#creates empty lists to store the data\n",
    "Name = []\n",
    "Date = []\n",
    "ARating = []\n",
    "\n",
    "\n",
    "#url for the site we were asked to scrape\n",
    "url = \"https://www.imdb.com/search/title/?groups=top_1000&count=100&sort=user_rating,desc\"\n",
    "browser.get(url)\n",
    "\n",
    "#starts page number counter at 1\n",
    "page_num = 1\n",
    "\n",
    "#loop to scrape through pages\n",
    "while True:\n",
    "    if page_num == 1:\n",
    "        print(f\"Scraping the {page_num}st set of 100...\") \n",
    "    elif page_num < 3: \n",
    "        print(f\"Scraping the {page_num}nd set of 100...\")\n",
    "    elif page_num == 3: \n",
    "        print(f\"Scraping the {page_num}rd set of 100...\")\n",
    "    elif page_num > 3: \n",
    "        print(f\"Scraping the {page_num}th set of 100...\")\n",
    "\n",
    "    #waits for a random time between 2 to 20 seconds\n",
    "    wait_time = random.randint(1, 2)\n",
    "    time.sleep(wait_time)\n",
    "\n",
    "    # Clear the previous data from the lists before appending the new set\n",
    "    Name.clear()\n",
    "    Date.clear()\n",
    "    ARating.clear()\n",
    "        \n",
    "    #scrolls to the bottom of the page\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "   \n",
    "    #scrapes name \n",
    "    name_elements = browser.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li/div/div/div/div[1]/div[2]/div[1]/a/h3')\n",
    "    for name in name_elements:\n",
    "        Name.append(name.text)\n",
    "\n",
    "    #scrapes date\n",
    "    date_elements = browser.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li/div/div/div/div[1]/div[2]/div[2]/span[1]')\n",
    "    for date in date_elements:\n",
    "        Date.append(date.text)\n",
    "\n",
    "    #finds all div elements with the specific class that contains movie metadata\n",
    "    movie_metadata_elements = browser.find_elements(By.CSS_SELECTOR, \"div.sc-300a8231-6.dBUjvq.dli-title-metadata\")\n",
    "\n",
    "    #iterate through each movie metadata element\n",
    "    for movie_metadata in movie_metadata_elements:\n",
    "        #find all span elements inside the current div\n",
    "        arating_elements = movie_metadata.find_elements(By.CSS_SELECTOR, \"span.sc-300a8231-7.eaXxft.dli-title-metadata-item\")\n",
    "\n",
    "        #checks if there are at least 3 elements (the third element is the rating)\n",
    "        if len(arating_elements) >= 3:\n",
    "            arating = arating_elements[2].text.strip()  #grabs the third span (the rating)\n",
    "            if arating:  #if the rating exists and isn't empty\n",
    "                ARating.append(arating)\n",
    "            else:\n",
    "                ARating.append(\"Not Rated\")  #appends \"Not Rated\" if no text is found\n",
    "        else:\n",
    "            ARating.append(\"Not Rated\")  #appends \"Not Rated\" if the third element doesn't exist\n",
    "   \n",
    "    \n",
    "     #hits the \"100 more\" button if there is one; if not, it ends the while loop and writes no more pages\n",
    "    try:\n",
    "        #locates the 100 more button using the XPath from the website\n",
    "        more_button = browser.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button/span/span')\n",
    "    \n",
    "        #clicks the 100 more button\n",
    "        more_button.click()\n",
    "    \n",
    "        #increments the set of 100 number\n",
    "        page_num += 1\n",
    "    \n",
    "        #waits for a short time before continuing to the set of 100\n",
    "        time.sleep(5)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        print(\"100 more button not found\")\n",
    "        break  #exits the loop if the button is not found\n",
    "\n",
    "    except ElementClickInterceptedException:\n",
    "        print(\"Could not click '100 more' button\")\n",
    "        break  #exits the loop if the button cannot be clicked\n",
    "\n",
    "print(f\"Length of Name: {len(Name)}\")\n",
    "print(f\"Length of Date: {len(Date)}\")\n",
    "print(f\"Length of ARating: {len(ARating)}\")\n",
    "\n",
    "\n",
    "\n",
    "#attaches the lists that were filled when scraped, to a column with the correct name\n",
    "IMDbT1 = pd.DataFrame({\n",
    "    \"Movie Name\": Name,\n",
    "    \"Release Date\": Date,\n",
    "    \"Audience Rating\": ARating\n",
    "})\n",
    "\n",
    "#saves dataframe to a csv file\n",
    "IMDbT1.to_csv(\"IMBbT1_raw.csv\", encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa869302-59f0-40d3-b7c1-02f6107cbd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Movie Name', 'Release Date', 'Audience Rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#checks the column names to verify that they are what we want\n",
    "print(IMDbT1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022941cd-aa86-4f35-a3dd-5cb066287239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strips any potential whitespace from column names\n",
    "IMDbT1.columns = IMDbT1.columns.str.strip()\n",
    "\n",
    "#splits Movie Name into Rank and Movie Name\n",
    "split_names = IMDbT1['Movie Name'].str.split('. ', n=1, expand=True)\n",
    "\n",
    "#assigns the split columns to the DataFrame\n",
    "IMDbT1['Rank'] = split_names[0].str.strip()  # The rank (before the period)\n",
    "IMDbT1['Movie_Name'] = split_names[1].str.strip()  # The movie name (after the period)\n",
    "\n",
    "#drops the original Movie Name column\n",
    "IMDbT1.drop('Movie Name', axis=1, inplace=True)\n",
    "\n",
    "#reorders columns to Rank, Movie Name, Release Date, and Audience Rating\n",
    "IMDbT1 = IMDbT1[['Rank', 'Movie_Name', 'Release Date', 'Audience Rating']]\n",
    "\n",
    "#renames the columns here to snake case\n",
    "IMDbT1 = IMDbT1.rename(columns={'Rank': 'rank', 'Movie_Name': 'movie_name', 'Release Date': 'release_date', 'Audience Rating': 'audience_rating'})\n",
    "\n",
    "#converts data types\n",
    "IMDbT1 = IMDbT1.astype({\n",
    "    'rank': 'int64',\n",
    "    'movie_name': 'string',\n",
    "    'release_date': 'int64',\n",
    "    'audience_rating': 'string'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "418b9944-ca09-4ca6-912e-286c6e7662da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves dataframe to a csv file\n",
    "IMDbT1.to_csv(\"IMDbT1_raw.csv\", encoding = \"utf-8\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
